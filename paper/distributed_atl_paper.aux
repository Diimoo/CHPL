\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{fodor1988connectionism,lake2018generalization}
\citation{radford2021learning}
\citation{li2022blip}
\citation{thrush2022winoground}
\citation{yuksekgonul2023vision}
\citation{rogers2004semantic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Compositionality Challenge}{1}{subsection.1.1}\protected@file@percent }
\citation{pouget2000information,kriegeskorte2015deep}
\citation{fodor1988connectionism}
\citation{lake2018generalization}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The Winner-Takes-All Bottleneck}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Our Approach: Distributed Semantic Binding}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Contributions}{2}{subsection.1.4}\protected@file@percent }
\citation{russin2019compositional}
\citation{andreas2016neural}
\citation{lake2019compositional}
\citation{higgins2018towards}
\citation{thrush2022winoground}
\citation{yuksekgonul2023vision}
\citation{ma2023crepe}
\citation{patterson2007you,lambon2017neural}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Distributed ATL Architecture.} Visual and language cortices encode inputs into 64-dimensional feature vectors. The Distributed ATL computes soft activation patterns over 200 prototypes using temperature-controlled softmax ($\tau =0.2$). Pattern similarity between visual and linguistic activations measures compositional binding quality. Hebbian learning updates prototypes weighted by activation strength.}}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:architecture}{{1}{3}{\textbf {Distributed ATL Architecture.} Visual and language cortices encode inputs into 64-dimensional feature vectors. The Distributed ATL computes soft activation patterns over 200 prototypes using temperature-controlled softmax ($\tau =0.2$). Pattern similarity between visual and linguistic activations measures compositional binding quality. Hebbian learning updates prototypes weighted by activation strength}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Compositional Generalization in AI}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Compositional Failures in Vision-Language Models}{3}{subsection.2.2}\protected@file@percent }
\citation{pouget2000information}
\citation{kriegeskorte2015deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Semantic Cognition and the Anterior Temporal Lobe}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Population Codes in Neuroscience}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Architecture Overview}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Visual Cortex}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Synthetic Images (56$\times $56)}{4}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Natural Images (224$\times $224)}{4}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Language Cortex}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Distributed ATL}{5}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Prototype Bank}{5}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Soft Activation Computation}{5}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Pattern Similarity}{5}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Hebbian Learning}{5}{subsubsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Training Protocol}{5}{subsection.3.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {Winner-Takes-All vs. Distributed ATL} on color holdout split.}}{6}{table.caption.2}\protected@file@percent }
\newlabel{tab:main_comparison}{{1}{6}{\textbf {Winner-Takes-All vs. Distributed ATL} on color holdout split}{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Datasets}{6}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Synthetic Two-Object Scenes}{6}{subsubsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Compositional Splits}{6}{subsubsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Hierarchical Scenes}{6}{subsubsection.3.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.4}COCO Natural Images}{6}{subsubsection.3.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Evaluation Metrics}{6}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Winner-Takes-All Fails on Composition}{6}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Main Comparison.} Distributed ATL achieves +29.6\% improvement over winner-takes-all baseline on held-out compositional scenes.}}{7}{figure.caption.3}\protected@file@percent }
\newlabel{fig:main_comparison}{{2}{7}{\textbf {Main Comparison.} Distributed ATL achieves +29.6\% improvement over winner-takes-all baseline on held-out compositional scenes}{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {Generalization across compositional splits.} All splits exceed 0.6 threshold and dramatically outperform baseline.}}{7}{table.caption.4}\protected@file@percent }
\newlabel{tab:splits}{{2}{7}{\textbf {Generalization across compositional splits.} All splits exceed 0.6 threshold and dramatically outperform baseline}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Generalization Across Compositional Splits}{7}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Variable Object Counts}{7}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Hierarchical Compositional Structure}{7}{subsection.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Generalization across compositional splits.} Distributed ATL maintains high similarity across all test conditions with minimal gaps.}}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:generalization}{{3}{8}{\textbf {Generalization across compositional splits.} Distributed ATL maintains high similarity across all test conditions with minimal gaps}{figure.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  {Variable object count generalization.} Training on 1-3 objects, testing on 4 objects (never seen).}}{8}{table.caption.6}\protected@file@percent }
\newlabel{tab:variable}{{3}{8}{\textbf {Variable object count generalization.} Training on 1-3 objects, testing on 4 objects (never seen)}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Natural Images (COCO)}{8}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Multi-Seed Validation and Ablations}{8}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Cognitive Capabilities (Phases 1-4)}{8}{subsection.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Adult-Level Capabilities (Phases 5-8)}{8}{subsection.4.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \textbf  {Hierarchical generalization.} Training on depth 1-2, testing on depth 3 (nested structures never seen).}}{9}{table.caption.7}\protected@file@percent }
\newlabel{tab:hierarchical}{{4}{9}{\textbf {Hierarchical generalization.} Training on depth 1-2, testing on depth 3 (nested structures never seen)}{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \textbf  {COCO natural image results.} Same architecture achieves higher similarity than synthetic with zero gap.}}{9}{table.caption.8}\protected@file@percent }
\newlabel{tab:coco}{{5}{9}{\textbf {COCO natural image results.} Same architecture achieves higher similarity than synthetic with zero gap}{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Why Distribution Matters for Composition}{9}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}The Role of Temperature}{9}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Synthetic to Natural Transfer}{9}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Visual grounding at scale.} The system grounds 28,489 words from processing 118k COCO images.}}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:grounding}{{4}{10}{\textbf {Visual grounding at scale.} The system grounds 28,489 words from processing 118k COCO images}{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \textbf  {Multi-seed validation} (n=5) confirms robustness.}}{10}{table.caption.10}\protected@file@percent }
\newlabel{tab:multiseed}{{6}{10}{\textbf {Multi-seed validation} (n=5) confirms robustness}{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}From Infant to Adult}{10}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Limitations}{10}{subsection.5.5}\protected@file@percent }
\bibstyle{plainnat}
\bibcite{andreas2016neural}{{1}{2016}{{Andreas et al.}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \textbf  {Temperature ablation.} $\tau =0.2$ achieves optimal balance between sparsity and distribution.}}{11}{table.caption.11}\protected@file@percent }
\newlabel{tab:temperature}{{7}{11}{\textbf {Temperature ablation.} $\tau =0.2$ achieves optimal balance between sparsity and distribution}{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Multi-seed validation.} All seeds exceed 0.6 threshold with consistent performance.}}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:multiseed}{{5}{11}{\textbf {Multi-seed validation.} All seeds exceed 0.6 threshold with consistent performance}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{11}{section.6}\protected@file@percent }
\bibcite{fodor1988connectionism}{{2}{1988}{{Fodor \& Pylyshyn}}{{}}}
\bibcite{higgins2018towards}{{3}{2018}{{Higgins et al.}}{{}}}
\bibcite{kriegeskorte2015deep}{{4}{2015}{{Kriegeskorte}}{{}}}
\bibcite{lake2019compositional}{{5}{2019}{{Lake}}{{}}}
\bibcite{lake2018generalization}{{6}{2018}{{Lake \& Baroni}}{{}}}
\bibcite{lambon2017neural}{{7}{2017}{{Lambon Ralph et al.}}{{}}}
\bibcite{li2022blip}{{8}{2022}{{Li et al.}}{{}}}
\bibcite{locatello2020object}{{9}{2020}{{Locatello et al.}}{{}}}
\bibcite{ma2023crepe}{{10}{2023}{{Ma et al.}}{{}}}
\bibcite{patterson2007you}{{11}{2007}{{Patterson et al.}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces \textbf  {Cognitive development results} (Phases 1-4, 8.3 min training).}}{12}{table.caption.13}\protected@file@percent }
\newlabel{tab:cognitive}{{8}{12}{\textbf {Cognitive development results} (Phases 1-4, 8.3 min training)}{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces \textbf  {Adult-level scaling} (Phases 5-8).}}{12}{table.caption.15}\protected@file@percent }
\newlabel{tab:adult}{{9}{12}{\textbf {Adult-level scaling} (Phases 5-8)}{table.caption.15}{}}
\bibcite{pouget2000information}{{12}{2000}{{Pouget et al.}}{{}}}
\bibcite{radford2021learning}{{13}{2021}{{Radford et al.}}{{}}}
\bibcite{rogers2004semantic}{{14}{2004}{{Rogers \& McClelland}}{{}}}
\bibcite{russin2019compositional}{{15}{2019}{{Russin et al.}}{{}}}
\bibcite{thrush2022winoground}{{16}{2022}{{Thrush et al.}}{{}}}
\bibcite{yuksekgonul2023vision}{{17}{2023}{{Yuksekgonul et al.}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Cognitive capabilities across development.} Same architecture achieves temporal prediction, causal inference, language generation, and analogical reasoning.}}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:cognitive}{{6}{13}{\textbf {Cognitive capabilities across development.} Same architecture achieves temporal prediction, causal inference, language generation, and analogical reasoning}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Developmental progression.} From infant perception through child reasoning to adult knowledge, all on the same Distributed ATL architecture.}}{14}{figure.caption.16}\protected@file@percent }
\newlabel{fig:developmental}{{7}{14}{\textbf {Developmental progression.} From infant perception through child reasoning to adult knowledge, all on the same Distributed ATL architecture}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Implementation Details}{14}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Compute Resources}{14}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Theoretical Analysis}{14}{appendix.C}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Capacity Analysis}{14}{subsection.C.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Temperature as Sparsity Control}{14}{subsection.C.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces \textbf  {Full hyperparameter table.}}}{15}{table.caption.19}\protected@file@percent }
\newlabel{tab:hyperparams}{{10}{15}{\textbf {Full hyperparameter table.}}{table.caption.19}{}}
\gdef \@abspage@last{15}
